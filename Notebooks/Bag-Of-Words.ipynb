{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from shutil import copyfile\n",
    "import html2text\n",
    "import re\n",
    "import logging\n",
    "import csv\n",
    "import enchant\n",
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from lxml import html\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_folder = os.path.join(os.path.expanduser('~'), 'Dropbox', 'Indigenous', 'Saved RA Documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_folder = os.path.join(os.getcwd(), 'html_files6' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Moving HTML Files to local directory\n",
    "filenames = []\n",
    "overwritten = []\n",
    "for index, filename in enumerate(glob.iglob('/home/jason/Dropbox/**/*.h*', recursive=True)):\n",
    "    basename = os.path.basename(filename)\n",
    "    out_filename = \"{}_{}\".format(basename, index)\n",
    "    file_dst = os.path.join(out_folder, out_filename)\n",
    "    copyfile(filename, file_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unwritten = []\n",
    "# clids = {}\n",
    "# clid_names = []\n",
    "parser = etree.HTMLParser()\n",
    "new_out = os.path.join(os.getcwd(), 'html_files_clid' )\n",
    "for index, file in enumerate(os.listdir(out_folder)):\n",
    "    html_doc = os.path.join(out_folder, file)\n",
    "    try:\n",
    "        tree = etree.parse(html_doc, parser)\n",
    "        clid = tree.xpath('/html/body/section/section/section/div[2]/p[1]//text()')[0].split(\": \",1)[1]\n",
    "        #clids[clid] = ''\n",
    "        #clid_names.append(clid)\n",
    "        out_name = \"{}.html\".format(clid)\n",
    "        out_loc = os.path.join(new_out, out_name)\n",
    "        copyfile(html_doc, out_loc)\n",
    "    except Exception as e:\n",
    "        #clids[file] = e\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtaining list of jbos we both possess\n",
    "joblist_csv = os.path.join(os.getcwd(), 'Relevant_Files', 'Regular_Use', 'JobList.csv')\n",
    "joblist = pd.read_csv(joblist_csv)\n",
    "all_jobs = list(map(lambda s: s.replace(\"\\\"\",\"\"),joblist['clid'].values))\n",
    "all_jobs_set = set(all_jobs)\n",
    "my_jobs = [os.path.splitext(x)[0] for x in os.listdir(new_out)]\n",
    "both_possess = all_jobs_set.intersection(my_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Moving into a Data folder\n",
    "out_path = os.path.join(os.getcwd(), 'Data')\n",
    "for index, file in enumerate(both_possess_paths):\n",
    "    out_loc = os.path.join(out_path, os.path.basename(file))\n",
    "    copyfile(file, out_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding the mutually missing HTML files\n",
    "my_jobs_set = set(my_jobs)\n",
    "brig_miss= np.asarray(list(my_jobs_set.difference(all_jobs_set)))\n",
    "me_miss = np.asarray(list(all_jobs_set.difference(my_jobs_set)))\n",
    "with open('missing_html.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['brig_missing'])\n",
    "    for i in brig_miss:\n",
    "        writer.writerow([i])\n",
    "with open('me_miss.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['me_missing'])\n",
    "    for i in me_miss:\n",
    "        writer.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_path = os.path.join(os.getcwd(), 'cant_read1.log')\n",
    "logging.basicConfig(filename = log_path, filemode = 'w')\n",
    "logging.info(\"HTML File Could Not be read\")\n",
    "logger = logging.getLogger(\"HTMLOpenError\")\n",
    "\n",
    "corpus_nocheck = []\n",
    "corpus_check = []\n",
    "notaword = []\n",
    "d = enchant.Dict(\"en_US\")\n",
    "# h = html2text.HTML2Text()\n",
    "# h.ignore_links = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_out = os.path.join(os.getcwd(), 'html_files5' )\n",
    "data_dir = os.path.join(os.getcwd(), 'Data')\n",
    "parser = etree.HTMLParser()\n",
    "corpus_body = {}\n",
    "for index, file in enumerate(os.listdir(data_dir)):\n",
    "    html_doc = os.path.join(data_dir, file)\n",
    "    try:\n",
    "        tree = etree.parse(html_doc, parser)\n",
    "        body_text = tree.xpath('//*[@id=\"postingbody\"]//text()')\n",
    "        body_text_str = ' '.join(body_text)\n",
    "        body_text_clean = body_text_str.rstrip().replace(\"\\n\",\"\")\n",
    "        clid = tree.xpath('/html/body/section/section/section/div[2]/p[1]//text()')[0].split(\": \",1)[1]\n",
    "        corpus_body[clid] = body_text_clean\n",
    "#         soup = BeautifulSoup(open(html_doc), \"html.parser\")\n",
    "#         #print(soup.find(id=\"postingbody\").text)\n",
    "#         finding_text = soup.find(id=\"postingbody\")\n",
    "#         text = (finding_text.text).rstrip()\n",
    "#         text_clean = re.sub(r'\\W+', '', text)\n",
    "#         corpus_body.append(text)\n",
    "#         tree = html.fromstring(soup)\n",
    "        \n",
    "    except:\n",
    "        print(index)\n",
    "        logger.exception(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.shutdown()\n",
    "#reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Obtain our bag of words\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "X = vectorizer.fit_transform(corpus_body.values())\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('words.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for i in words:\n",
    "        writer.writerow([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Remove all non-words and present as dataframe\n",
    "# words_only = np.asarray(words[2493:])\n",
    "# words_only_values = X.toarray()[:,2493:]\n",
    "# bag_of_words_df = pd.DataFrame(words_only_values, columns = words_only, index = corpus_body.keys())\n",
    "# word_counts = bag_of_words_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Loading all dropped words\n",
    "# dropped_words = pd.read_csv('dropped_words.csv')\n",
    "# dropped_words_values = dropped_words['dropped_word'].dropna().values\n",
    "# bag_of_words_df.drop(dropped_words_values, axis = 1, inplace = True) #Drop the dropped words\n",
    "# bag_of_words_df.to_csv('bag_of_words_>10.csv') #Save occurrences greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subsetting words only with 100+ occurrences\n",
    "word_counts_df = pd.read_csv('word_counts.csv')\n",
    "word_100 = word_counts_df[word_counts_df['count'] >= 100]['word'].values\n",
    "bag_of_words_100 = bag_of_words_df[word_100]\n",
    "bag_of_words_100.to_csv('bag_of_words_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Obtaining a subset of words with more than 100 occurrences\n",
    "# bag_of_words_df\n",
    "# with open('word_occurrences_100+.csv', 'r') as f:\n",
    "#     csvreader = csv.reader(f)\n",
    "#     next(csvreader, None)\n",
    "#     word_choice = [row[0] for row in csvreader]\n",
    "#     f.close()\n",
    "# word_choice\n",
    "# bag_of_words_df_subset = bag_of_words_df[word_choice]\n",
    "# bag_of_words_df_subset.to_csv('bag_of_words_100+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Acquiring Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Used to label as discriminated if callback for nonminority is 1 and callback for minority is zero\n",
    "def discriminate(row):\n",
    "    if row['indigenous_discrimination'] == 1 or row['reverse_discrimination'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "#Used to label as discriminated if callback for nonminority is 1 and callback for minority is zero\n",
    "def reverse_discriminate(row):\n",
    "    if row['callback_non_minority'] == 0 and row['callback_minority'] == 1:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "def forward_reverse_discriminate(row):\n",
    "    if row['callback_non_minority'] == 1.0 and row['callback_minority'] == 0 :\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preparing data\n",
    "labor_discrim_data = os.path.join(os.getcwd(),'full_data - Jason.dta')\n",
    "\n",
    "l_discrim_df = pd.read_stata(labor_discrim_data, index_col = 'clid', columns = ['clid', 'callback', 'indigenous'])\n",
    "l_discrim_df.index = l_discrim_df.index.map(str)\n",
    "l_discrim_nonminority = l_discrim_df[l_discrim_df['indigenous'] == 0].rename(index=str, \n",
    "                                                                          columns = {\"callback\": \"callback_non_minority\"}).drop(['indigenous'], axis = 1)\n",
    "l_discrim_minority = l_discrim_df[l_discrim_df['indigenous'] == 1].rename(index=str, \n",
    "                                                                          columns = {\"callback\": \"callback_minority\"}).drop(['indigenous'], axis = 1)\n",
    "l_discrim_fin = l_discrim_nonminority.join(l_discrim_minority, how='outer')\n",
    "l_discrim_fin['discriminated'] = l_discrim_fin.apply(discriminate, axis = 1)\n",
    "l_discrim_fin.to_csv('flattened_discriminated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discrim_labels = pd.read_csv('flattened_discriminated.csv', index_col = 'clid')\n",
    "bag_of_words_100 = pd.read_csv('bag_of_words_100+.csv', index_col = 'clid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possessed_ads = set(bag_of_words_100.index.values)\n",
    "all_ads = set(discrim_labels.index.values)\n",
    "labels_to_drop = (all_ads.difference(possessed_ads))\n",
    "word_rows_to_drop = possessed_ads.difference(all_ads)\n",
    "discrim_labels_possessed = discrim_labels.drop(labels_to_drop)\n",
    "bag_of_words_possessed = bag_of_words_100.drop(word_rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words_labels = bag_of_words_possessed.join(discrim_labels_possessed, how='outer').dropna()\n",
    "bag_of_words_labels.to_csv('labor_discrim_whole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting inconsistency in amount between labeled ADS and the ads I possess\n",
    "labeled_clid = pd.read_csv('flattened_discriminated.csv', index_col = 'clid')\n",
    "clids = set([str(x).split('.')[0] for x in labeled_clid.index.values])\n",
    "data_jobs = [os.path.splitext(x)[0] for x in os.listdir('Data')]\n",
    "data_jobs_set = set(data_jobs)\n",
    "i_possess_labels = clids.intersection(data_jobs)\n",
    "i_miss = clids.difference(data_jobs)\n",
    "label_miss = data_jobs_set.difference(clids)\n",
    "print(\"Labeled Jobs I have: {}\".format(len(i_possess_labels)))\n",
    "print(\"Labeled Jobs I am Missing: {}\".format(len(i_miss)))\n",
    "print(\"Missing Labels for {} jobs\".format(len(label_miss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Labels for Reverse Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_whole = '/home/jason/Documents/Labor_Discrimination/labor_discrim_whole.csv'\n",
    "labor_discrim_df = pd.read_csv(labor_discrim_whole, index_col='clid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_df['discrimination'] = labor_discrim_df.apply (lambda row: discriminate(row),axis=1)\n",
    "labor_discrim_df['reverse_discrimination'] = labor_discrim_df.apply (lambda row: reverse_discriminate(row),axis=1)\n",
    "labor_discrim_df.to_csv('labor_discrim_whole.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_df.to_csv('labor_discrim_presence.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso-Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_whole = os.path.join(os.getcwd(), 'Relevant_Files', 'Regular_Use', 'labor_discrim_whole.csv')\n",
    "bag_of_words_labels = pd.read_csv(labor_discrim_whole, index_col = 'clid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = bag_of_words_labels.drop(['callback_non_minority', 'callback_minority', 'discriminated'], axis = 1).as_matrix()\n",
    "y = bag_of_words_labels['discriminated'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_clf = LogisticRegression(penalty='l1')\n",
    "logit_clf.fit(X_data, y) #Fit on data\n",
    "coef_values = logit_clf.coef_[logit_clf.coef_ != 0] #Obtain all non-removed coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470,)\n",
      "(1, 740)\n"
     ]
    }
   ],
   "source": [
    "print(coef_values.shape)\n",
    "print(logit_clf.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_features = bag_of_words_labels.drop(['callback_non_minority', 'callback_minority', 'discriminated'], axis = 1).columns.values\n",
    "word_coef = np.column_stack((X_features,logit_clf.coef_.reshape((740))) )\n",
    "word_coef_nonzero = word_coef[word_coef[:,1] != 0]\n",
    "word_coef_df = pd.DataFrame(word_coef).to_csv('word_weights_all.csv')\n",
    "word_coef_nonzero_df = pd.DataFrame(word_coef_nonzero).to_csv('word_weights_nonzero.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso-Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_all = []\n",
    "for res in results:\n",
    "    low, upp = res.confint().T   # unpack columns \n",
    "    res_all.append(numpy.concatenate(([res.llf], res.params, res.tvalues, res.pvalues, \n",
    "                   low, upp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example: http://www.statsmodels.org/stable/examples/notebooks/generated/discrete_choice_overview.html\n",
    "#Other Examples: http://www.statsmodels.org/stable/examples/index.html#discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labor_discrim_whole = os.path.join(os.getcwd(), 'Relevant_Files', 'Regular_Use', 'labor_discrim_whole.csv')\n",
    "bag_of_words_labels = pd.read_csv(labor_discrim_whole, index_col = 'clid')\n",
    "Bag_of_Words = bag_of_words_labels.drop(['callback_non_minority', 'callback_minority', 'indigenous_discrimination',\n",
    "                                        'reverse_discrimination','discrimination'], axis = 1).as_matrix()\n",
    "X = sm.add_constant(Bag_of_Words, prepend = False)\n",
    "indig_y = bag_of_words_labels['indigenous_discrimination'].as_matrix()\n",
    "reverse_y = bag_of_words_labels['reverse_discrimination'].as_matrix()\n",
    "discrim_y = bag_of_words_labels['discrimination'].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probit_mod_indig = sm.Probit(indig_y, X, method = 'bfgs') # bfgs since the hessian was non singular\n",
    "probit_mod_rev = sm.Probit(reverse_y, X, method = 'bfgs')\n",
    "probit_mod_all = sm.Probit(discrim_y, X, method = 'bfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.12725896602336798\n",
      "            Iterations: 566\n",
      "            Function evaluations: 567\n",
      "            Gradient evaluations: 566\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.13559873297359373\n",
      "            Iterations: 587\n",
      "            Function evaluations: 589\n",
      "            Gradient evaluations: 587\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.24352531691899312\n",
      "            Iterations: 428\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 428\n"
     ]
    }
   ],
   "source": [
    "probit_res_indig = probit_mod_indig.fit_regularized(method = 'l1', disp=True, alpha = 1)\n",
    "probit_res_rev = probit_mod_rev.fit_regularized(method = 'l1', disp=True, alpha = 1)\n",
    "probit_res_all = probit_mod_all.fit_regularized(method = 'l1', disp=True, alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experience',\n",
       " 'work',\n",
       " 'resume',\n",
       " 'time',\n",
       " 'looking',\n",
       " 'team',\n",
       " 'service',\n",
       " 'email',\n",
       " 'able',\n",
       " 'position',\n",
       " 'skills',\n",
       " 'restaurant',\n",
       " 'food',\n",
       " 'available',\n",
       " 'required',\n",
       " 'job',\n",
       " 'hours',\n",
       " 'environment',\n",
       " 'working',\n",
       " 'customer',\n",
       " 'high',\n",
       " 'apply',\n",
       " 'ability',\n",
       " 'great',\n",
       " 'seeking',\n",
       " 'company',\n",
       " 'include',\n",
       " 'send',\n",
       " 'line',\n",
       " 'years',\n",
       " 'clean',\n",
       " 'plus',\n",
       " 'hiring',\n",
       " 'weekends',\n",
       " 'positions',\n",
       " 'join',\n",
       " 'requirements',\n",
       " 'fast',\n",
       " 'duties',\n",
       " 'person',\n",
       " 'reliable',\n",
       " 'knowledge',\n",
       " 'com',\n",
       " 'kitchen',\n",
       " 'preferred',\n",
       " 'cook',\n",
       " 'new',\n",
       " 'professional',\n",
       " 'shifts',\n",
       " 'pay',\n",
       " 'good',\n",
       " 'experienced',\n",
       " 'week',\n",
       " 'responsibilities',\n",
       " 'excellent',\n",
       " 'flexible',\n",
       " 'cleaning',\n",
       " 'opportunity',\n",
       " 'attitude',\n",
       " 'people',\n",
       " 'customers',\n",
       " 'cooks',\n",
       " 'positive',\n",
       " 'needed',\n",
       " 'schedule',\n",
       " 'friendly',\n",
       " 'open',\n",
       " 'including',\n",
       " 'strong',\n",
       " 'paced',\n",
       " 'communication',\n",
       " 'candidates',\n",
       " 'interested',\n",
       " 'staff',\n",
       " 'day',\n",
       " 'contact',\n",
       " 'benefits',\n",
       " 'following',\n",
       " 'phone',\n",
       " 'sales',\n",
       " 'maintain',\n",
       " 'responsible',\n",
       " 'background',\n",
       " 'availability',\n",
       " 'shift',\n",
       " 'prep',\n",
       " 'located',\n",
       " 'qualifications',\n",
       " 'need',\n",
       " 'check',\n",
       " 'days',\n",
       " 'motivated',\n",
       " 'security',\n",
       " 'currently',\n",
       " 'individuals',\n",
       " 'training',\n",
       " 'provide',\n",
       " 'hour',\n",
       " 'learn',\n",
       " 'store',\n",
       " 'area',\n",
       " 'quality',\n",
       " 'year',\n",
       " 'lift',\n",
       " 'license',\n",
       " 'make',\n",
       " 'interview',\n",
       " 'reply',\n",
       " 'retail',\n",
       " 'transportation',\n",
       " 'location',\n",
       " 'management',\n",
       " 'willing',\n",
       " 'holidays',\n",
       " 'candidate',\n",
       " 'employees',\n",
       " 'offer',\n",
       " 'applicants',\n",
       " 'monday',\n",
       " 'friday',\n",
       " 'information',\n",
       " 'maintenance',\n",
       " 'respond',\n",
       " 'hard',\n",
       " 'school',\n",
       " 'help',\n",
       " 'equipment',\n",
       " 'fun',\n",
       " 'minimum',\n",
       " 'daily',\n",
       " 'right',\n",
       " 'necessary',\n",
       " 'employment',\n",
       " 'business',\n",
       " 'servers',\n",
       " 'valid',\n",
       " 'bar',\n",
       " 'come',\n",
       " 'pass',\n",
       " 'start',\n",
       " 'follow',\n",
       " 'competitive',\n",
       " 'general',\n",
       " 'previous',\n",
       " 'based',\n",
       " 'pm',\n",
       " 'immediate',\n",
       " 'basic',\n",
       " 'areas',\n",
       " 'energetic',\n",
       " 'oriented',\n",
       " 'card',\n",
       " 'standards',\n",
       " 'drug',\n",
       " 'english',\n",
       " 'safety',\n",
       " 'hire',\n",
       " 'long',\n",
       " 'paid',\n",
       " 'perform',\n",
       " 'guests',\n",
       " 'best',\n",
       " 'orders',\n",
       " 'chef',\n",
       " 'products',\n",
       " 'like',\n",
       " 'health',\n",
       " 'forward',\n",
       " 'busy',\n",
       " 'nights',\n",
       " 'self',\n",
       " 'www',\n",
       " 'level',\n",
       " 'ensure',\n",
       " 'dining',\n",
       " 'industry',\n",
       " 'locations',\n",
       " 'set',\n",
       " 'qualified',\n",
       " 'tasks',\n",
       " 'growing',\n",
       " 'saturday',\n",
       " 'needs',\n",
       " 'manager',\n",
       " 'current',\n",
       " 'services',\n",
       " 'employee',\n",
       " 'player',\n",
       " 'weekend',\n",
       " 'train',\n",
       " 'building',\n",
       " 'cooking',\n",
       " 'multi',\n",
       " 'assist',\n",
       " 'medical',\n",
       " 'volume',\n",
       " 'grow',\n",
       " 'immediately',\n",
       " 'menu',\n",
       " 'items',\n",
       " 'organized',\n",
       " 'members',\n",
       " 'opening',\n",
       " 'application',\n",
       " 'assigned',\n",
       " 'employer',\n",
       " 'guard',\n",
       " 'server',\n",
       " 'ideal',\n",
       " 'want',\n",
       " 'serving',\n",
       " 'procedures',\n",
       " 'submit',\n",
       " 'attention',\n",
       " 'local',\n",
       " 'compensation',\n",
       " 'meet',\n",
       " 'stand',\n",
       " 'maintaining',\n",
       " 'communicate',\n",
       " 'opportunities',\n",
       " 'house',\n",
       " 'limited',\n",
       " 'manner',\n",
       " 'family',\n",
       " 'insurance',\n",
       " 'look',\n",
       " 'passion',\n",
       " 'times',\n",
       " 'outgoing',\n",
       " 'love',\n",
       " 'equal',\n",
       " 'use',\n",
       " 'individual',\n",
       " 'appearance',\n",
       " 'prior',\n",
       " 'sunday',\n",
       " 'diploma',\n",
       " 'providing',\n",
       " 'product',\n",
       " 'room',\n",
       " 'cover',\n",
       " 'free',\n",
       " 'inventory',\n",
       " 'possess',\n",
       " 'handling',\n",
       " 'starting',\n",
       " 'driver',\n",
       " 'thank',\n",
       " 'growth',\n",
       " 'walk',\n",
       " 'hospitality',\n",
       " 'resumes',\n",
       " 'letter',\n",
       " 'number',\n",
       " 'complete',\n",
       " 'passionate',\n",
       " 'description',\n",
       " 'janitorial',\n",
       " 'dental',\n",
       " 'task',\n",
       " 'making',\n",
       " 'handle',\n",
       " 'trash',\n",
       " 'dependable',\n",
       " 'calls',\n",
       " 'ethic',\n",
       " 'office',\n",
       " 'computer',\n",
       " 'dishwasher',\n",
       " 'read',\n",
       " 'night',\n",
       " 'highly',\n",
       " 'small',\n",
       " 'effectively',\n",
       " 'serve',\n",
       " 'order',\n",
       " 'career',\n",
       " 'place',\n",
       " 'ad',\n",
       " 'considered',\n",
       " 'written',\n",
       " 'state',\n",
       " 'lunch',\n",
       " 'lbs',\n",
       " 'shop',\n",
       " 'vision',\n",
       " 'speak',\n",
       " 'guest',\n",
       " 'hr',\n",
       " 'vacation',\n",
       " 'cash',\n",
       " 'personality',\n",
       " 'record',\n",
       " 'related',\n",
       " 'salary',\n",
       " 'wine',\n",
       " 'city',\n",
       " 'enjoy',\n",
       " 'physical',\n",
       " 'floor',\n",
       " 'prepare',\n",
       " 'proper',\n",
       " 'personal',\n",
       " 'safe',\n",
       " 'care',\n",
       " 'provided',\n",
       " 'pounds',\n",
       " 'property',\n",
       " 'reports',\n",
       " 'essential',\n",
       " 'hourly',\n",
       " 'cafe',\n",
       " 'using',\n",
       " 'pressure',\n",
       " 'grill',\n",
       " 'periods',\n",
       " 'established',\n",
       " 'offers',\n",
       " 'subject',\n",
       " 'brooklyn',\n",
       " 'multiple',\n",
       " 'sense',\n",
       " 'cashier',\n",
       " 'exceptional',\n",
       " 'cleanliness',\n",
       " 'just',\n",
       " 'preparation',\n",
       " 'consideration',\n",
       " 'education',\n",
       " 'evenings',\n",
       " 'community',\n",
       " 'potential',\n",
       " 'various',\n",
       " 'center',\n",
       " 'los',\n",
       " 'age',\n",
       " 'ready',\n",
       " 'requires',\n",
       " 'advancement',\n",
       " 'dishes',\n",
       " 'enthusiastic',\n",
       " 'punctual',\n",
       " 'understand',\n",
       " 'taking',\n",
       " 'evening',\n",
       " 'includes',\n",
       " 'casual',\n",
       " 'dedicated',\n",
       " 'dinner',\n",
       " 'history',\n",
       " 'associate',\n",
       " 'events',\n",
       " 'supplies',\n",
       " 'type',\n",
       " 'life',\n",
       " 'morning',\n",
       " 'interviews',\n",
       " 'restaurants',\n",
       " 'culinary',\n",
       " 'depending',\n",
       " 'mail',\n",
       " 'feel',\n",
       " 'street',\n",
       " 'test',\n",
       " 'don',\n",
       " 'york',\n",
       " 'ca',\n",
       " 'know',\n",
       " 'stock',\n",
       " 'fine',\n",
       " 'ingredients',\n",
       " 'member',\n",
       " 'owned',\n",
       " 'special',\n",
       " 'department',\n",
       " 'group',\n",
       " 'light',\n",
       " 'operations',\n",
       " 'associates',\n",
       " 'timely',\n",
       " 'sanitation',\n",
       " 'desire',\n",
       " 'dishwashers',\n",
       " 'driving',\n",
       " 'supervisor',\n",
       " 'home',\n",
       " 'certification',\n",
       " 'recipes',\n",
       " 'cuisine',\n",
       " 'end',\n",
       " 'possible',\n",
       " 'carry',\n",
       " 'driven',\n",
       " 'tips',\n",
       " 'verbal',\n",
       " 'write',\n",
       " 'equivalent',\n",
       " 'criminal',\n",
       " 'performance',\n",
       " 'visit',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'downtown',\n",
       " 'hearing',\n",
       " 'facility',\n",
       " 'stop',\n",
       " 'applying',\n",
       " 'efficient',\n",
       " 'applications',\n",
       " 'coffee',\n",
       " 'control',\n",
       " 'west',\n",
       " 'ave',\n",
       " 'clients',\n",
       " 'body',\n",
       " 'instructions',\n",
       " 'copy',\n",
       " 'floors',\n",
       " 'quickly',\n",
       " 'workers',\n",
       " 'functions',\n",
       " 'la',\n",
       " 'officers',\n",
       " 'policies',\n",
       " 'support',\n",
       " 'host',\n",
       " 'independently',\n",
       " 'references',\n",
       " 'understanding',\n",
       " 'brand',\n",
       " 'commercial',\n",
       " 'exciting',\n",
       " 'report',\n",
       " 'create',\n",
       " 'successful',\n",
       " 'asap',\n",
       " 'process',\n",
       " 'angeles',\n",
       " 'program',\n",
       " 'station',\n",
       " 'vehicle',\n",
       " 'bartenders',\n",
       " 'hand',\n",
       " 'online',\n",
       " 'sweeping',\n",
       " 'today',\n",
       " 'counter',\n",
       " 'houston',\n",
       " 'st',\n",
       " 'weekly',\n",
       " 'honolulu',\n",
       " 'setting',\n",
       " 'fit',\n",
       " 'works',\n",
       " 'mopping',\n",
       " 'public',\n",
       " 'seasonal',\n",
       " 'tuesday',\n",
       " 'ny',\n",
       " 'fresh',\n",
       " 'handlers',\n",
       " 'organization',\n",
       " 'organizational',\n",
       " 'willingness',\n",
       " 'ged',\n",
       " 'pride',\n",
       " 'certificate',\n",
       " 'hotel',\n",
       " 'market',\n",
       " 'tables',\n",
       " 'tools',\n",
       " 'attach',\n",
       " 'breakfast',\n",
       " 'repairs',\n",
       " 'according',\n",
       " 'assisting',\n",
       " 'officer',\n",
       " 'quick',\n",
       " 'schedules',\n",
       " 'site',\n",
       " 'lead',\n",
       " 'old',\n",
       " 'plan',\n",
       " 'professionals',\n",
       " 'beverage',\n",
       " 'bonus',\n",
       " 'operate',\n",
       " 'openings',\n",
       " 'supervision',\n",
       " 'common',\n",
       " 'handler',\n",
       " 'months',\n",
       " 'efficiently',\n",
       " 'applicant',\n",
       " 'different',\n",
       " 'direction',\n",
       " 'energy',\n",
       " 'interpersonal',\n",
       " 'questions',\n",
       " 'thursday',\n",
       " 'variety',\n",
       " 'welcome',\n",
       " 'world',\n",
       " 'drive',\n",
       " 'knife',\n",
       " 'nyc',\n",
       " 'pos',\n",
       " 'washing',\n",
       " 'close',\n",
       " 'focused',\n",
       " 'provides',\n",
       " 'stocking',\n",
       " 'ask',\n",
       " 'lifting',\n",
       " 'posting',\n",
       " 'preparing',\n",
       " 'summary',\n",
       " 'term',\n",
       " 'atmosphere',\n",
       " 'hardworking',\n",
       " 'meeting',\n",
       " 'situations',\n",
       " 'windows',\n",
       " 'az',\n",
       " 'unique',\n",
       " 'basis',\n",
       " 'drivers',\n",
       " 'hawaii',\n",
       " 'north',\n",
       " 'add',\n",
       " 'appropriate',\n",
       " 'bring',\n",
       " 'demeanor',\n",
       " 'issues',\n",
       " 'law',\n",
       " 'maintains',\n",
       " 'plumbing',\n",
       " 'style',\n",
       " 'table',\n",
       " 'electrical',\n",
       " 'painting',\n",
       " 'social',\n",
       " 'thanks',\n",
       " 'fashion',\n",
       " 'spanish',\n",
       " 'way',\n",
       " 'website',\n",
       " 'neat',\n",
       " 'committed',\n",
       " 'list',\n",
       " 'outstanding',\n",
       " 'relationships',\n",
       " 'vacuuming',\n",
       " 'wage',\n",
       " 'bartender',\n",
       " 'keeping',\n",
       " 'systems',\n",
       " 'fax',\n",
       " 'blvd',\n",
       " 'helpful',\n",
       " 'info',\n",
       " 'japanese',\n",
       " 'operation',\n",
       " 'rate',\n",
       " 'receive',\n",
       " 'activities',\n",
       " 'barista',\n",
       " 'goals',\n",
       " 'helping',\n",
       " 'national',\n",
       " 'standing',\n",
       " 'upscale',\n",
       " 'client',\n",
       " 'heart',\n",
       " 'hostess',\n",
       " 'non',\n",
       " 'soon',\n",
       " 'stores',\n",
       " 'addition',\n",
       " 'comfortable',\n",
       " 'neighborhood',\n",
       " 'phoenix',\n",
       " 'satisfaction',\n",
       " 'scheduled',\n",
       " 'sure',\n",
       " 'concept',\n",
       " 'delivery',\n",
       " 'focus',\n",
       " 'important',\n",
       " 'merchandise',\n",
       " 'multitask',\n",
       " 'pre',\n",
       " 'assistant',\n",
       " 'goal',\n",
       " 'janitor',\n",
       " 'key',\n",
       " 'little',\n",
       " 'managers',\n",
       " 'production',\n",
       " 'regulations',\n",
       " 'require',\n",
       " 'sick',\n",
       " 'status',\n",
       " 'american',\n",
       " 'beer',\n",
       " 'closing',\n",
       " 'personnel',\n",
       " 'restrooms',\n",
       " 'role',\n",
       " 'feet',\n",
       " 'guidelines',\n",
       " 'lot',\n",
       " 'seeks',\n",
       " 'word',\n",
       " 'access',\n",
       " 'creative',\n",
       " 'early',\n",
       " 'meal',\n",
       " 'pdf',\n",
       " 'takes',\n",
       " 'wages',\n",
       " 'worker',\n",
       " 'checks',\n",
       " 'conditions',\n",
       " 'direct',\n",
       " 'highest',\n",
       " 'meals',\n",
       " 'package',\n",
       " 'park',\n",
       " 'think',\n",
       " 'money',\n",
       " 'outside',\n",
       " 'reach',\n",
       " 'run',\n",
       " 'change',\n",
       " 'creating',\n",
       " 'heavy',\n",
       " 'italian',\n",
       " 'guards',\n",
       " 'leave',\n",
       " 'performing',\n",
       " 'requests',\n",
       " 'sell',\n",
       " 'talented',\n",
       " 'amazing',\n",
       " 'attached',\n",
       " 'hi',\n",
       " 'jobs',\n",
       " 'learning',\n",
       " 'live',\n",
       " 'locally',\n",
       " 'operating',\n",
       " 'range',\n",
       " 'register',\n",
       " 'regular',\n",
       " 'screening',\n",
       " 'waikiki',\n",
       " 'consistent',\n",
       " 'east',\n",
       " 'ensuring',\n",
       " 'manage',\n",
       " 'commitment',\n",
       " 'date',\n",
       " 'demonstrate',\n",
       " 'large',\n",
       " 'unarmed',\n",
       " 'beach',\n",
       " 'craft',\n",
       " 'flexibility',\n",
       " 'near',\n",
       " 'residents',\n",
       " 'bilingual',\n",
       " 'chicago',\n",
       " 'emergency',\n",
       " 'entry',\n",
       " 'grounds',\n",
       " 'major',\n",
       " 'period',\n",
       " 'short',\n",
       " 'states',\n",
       " 'success',\n",
       " 'wanted',\n",
       " 'cashiers',\n",
       " 'catering',\n",
       " 'drinks',\n",
       " 'gmail',\n",
       " 'parking',\n",
       " 'techniques',\n",
       " 'details',\n",
       " 'disability',\n",
       " 'primary',\n",
       " 'rooms',\n",
       " 'answer',\n",
       " 'degree',\n",
       " 'dynamic',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'desired',\n",
       " 'field',\n",
       " 'integrity',\n",
       " 'scheduling',\n",
       " 'buildings',\n",
       " 'california',\n",
       " 'facilities',\n",
       " 'sat',\n",
       " 'standard',\n",
       " 'bakery',\n",
       " 'honest',\n",
       " 'knowledgeable',\n",
       " 'patrol',\n",
       " 'pizza',\n",
       " 'responsibility',\n",
       " 'brunch',\n",
       " 'courteous',\n",
       " 'culture',\n",
       " 'merchandising',\n",
       " 'mon',\n",
       " 'skill',\n",
       " 'apartment',\n",
       " 'believe',\n",
       " 'furniture',\n",
       " 'greet',\n",
       " 'performs',\n",
       " 'pick',\n",
       " 'selling',\n",
       " 'summer',\n",
       " 'united',\n",
       " 'build',\n",
       " 'cell',\n",
       " 'drop',\n",
       " 'hands',\n",
       " 'hot',\n",
       " 'text',\n",
       " 'brief',\n",
       " 'deliver',\n",
       " 'develop',\n",
       " 'directly',\n",
       " 'discounts',\n",
       " 'holiday']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bag_of_words_labels.columns[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/labordiscrim/lib/python3.5/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/jason/anaconda3/envs/labordiscrim/lib/python3.5/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/jason/anaconda3/envs/labordiscrim/lib/python3.5/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "summary_indig = probit_res_indig.summary(xname = list(bag_of_words_labels.columns[:-5])+ ['const']) #Get summary with variable names\n",
    "summary_rev = probit_res_rev.summary(xname = list(bag_of_words_labels.columns[:-5])+ ['const']) #Get summary with variable names\n",
    "probit_res_all = probit_res_all.summary(xname = list(bag_of_words_labels.columns[:-5])+ ['const']) #Get summary with variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
